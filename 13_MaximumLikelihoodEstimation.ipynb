{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최대우도추정법(Maximum Likelihood Estimation)\n",
    "\n",
    "# 최대우도추정법 (Maximum Likelihood Estimation)\n",
    "\n",
    "## 1. 개요\n",
    "최대우도추정법(MLE)은 주어진 데이터에서 확률 분포의 매개변수를 추정하는 방법입니다. 이 방법은 관측된 데이터가 주어진 확률 분포에서 발생할 가능성을 최대화하는 매개변수를 찾는 것이 목표입니다. MLE는 주로 통계 모델링 및 기계 학습에서 널리 사용됩니다.\n",
    "\n",
    "## 2. 기본 개념\n",
    "\n",
    "- **1)확률(Probability)**:\n",
    "  - 확률은 어떤 사건이 발생할 가능성을 나타내는 수치로, 0과 1 사이의 값을 가집니다. 확률이 0이면 사건이 절대 발생하지 않음을 의미하고, 확률이 1이면 사건이 확실히 발생함을 의미합니다.\n",
    "  - 확률을 구하는 식은 다음과 같습니다:\n",
    "    $$\n",
    "    P(A) = \\frac{\\text{이벤트 A가 발생한 횟수}}{\\text{전체 실험 횟수}}\n",
    "    $$\n",
    "  - 예를 들어, 동전을 던졌을 때 앞면이 나올 확률은 0.5입니다. 이는 동전이 공평할 때, 앞면이 나올 가능성이 50%라는 것을 의미합니다.\n",
    "  - 또 다른 예로, 공정한 주사위를 던졌을 때 특정 숫자 3이 나올 확률은 1/6입니다. 이는 주사위의 모든 면이 동일한 확률로 나타날 것이라는 가정하에, 특정 면이 나올 가능성이 16.67%임을 나타냅니다.\n",
    "\n",
    "- **2)연속사건의 확률과 확률밀도함수(Probability Density Function, PDF)**:\n",
    "  - 주사위의 경우를 확장에서, 1부터 6 사이의 실수에서 3이 나올 확률은 0입니다. 위의 식에서 '전체 실험횟수'가 무한대이기 때문이죠.\n",
    "  - 이와 같은 연속적인 변수의 경우, 특정 값에서의 확률을 구하는 것이 아니라 특정 구간 내에서 변수의 값이 발생할 확률을 구합니다.\n",
    "  - 이때 확률 밀도 함수(Probability Density Function, PDF)를 사용하여 확률을 계산합니다. PDF는 변수의 특정 값에서의 상대적 가능성을 나타내며, 특정 구간에 대한 확률은 PDF를 그 구간에서 적분하여 구합니다.\n",
    "\n",
    "    $$\n",
    "    P(a \\leq X \\leq b) = \\int_{a}^{b} f(x) \\, dx\n",
    "    $$\n",
    "    여기서 `f(x)`는 확률 밀도 함수입니다.\n",
    "  - 예를 들어, 사람의 키가 정규 분포를 따르는 경우, 키가 170cm에서 180cm 사이에 있을 확률은 PDF를 170과 180 사이에서 적분하여 구합니다.\n",
    "  - 이 확률은 특정 값이 아닌 구간에 대한 것이므로, PDF 값은 직접적인 확률이 아니라 확률의 밀도를 나타냅니다.\n",
    "  - 연속사건에서는 특정 값에서의 확률이 0인 이유는, 연속 변수의 경우 가능한 값이 무수히 많기 때문에 특정 값 하나에 대한 확률은 0으로 간주됩니다.\n",
    "  - 따라서 `특정 구간에 대해 확률을 계산해야만 의미 있는 확률을 구할 수 있습니다.`\n",
    "\n",
    "\n",
    "#### 3) 가능도(= 우도, Likelihood)\n",
    "\n",
    "- **1) 개요**\n",
    "  - 가능도는 주어진 데이터가 특정 확률 분포의 매개변수로부터 생성될 가능성을 측정하는 함수입니다. 데이터가 특정 매개변수 값 하에서 얼마나 잘 설명되는지를 나타내는 데 사용됩니다.\n",
    "  - **셈할 수 있는 사건** (예: 동전 던지기, 주사위 던지기)에서는 가능도가 실제 확률과 일치합니다. 예를 들어, 동전 던지기에서 동전이 앞면이 나올 확률이 0.5일 때, 해당 확률은 가능도와 같습니다.\n",
    "  - **연속 사건**에서는 가능도가 확률 밀도 함수(PDF)의 값과 같으며, 특정 값의 확률이 아닌 밀도를 제공합니다. 즉, 특정 구간 내에서의 확률을 계산하기 위해서는 PDF 값을 적분해야 합니다.\n",
    "\n",
    "- **2) 가능도 함수(Likelihood Function)**\n",
    "  - 가능도 함수는 주어진 매개변수에 대해 데이터가 관측될 확률을 나타내는 함수입니다. 주어진 데이터 집합과 특정 매개변수를 사용하여 데이터가 발생할 확률을 평가합니다.\n",
    "  - **최대우도추정법(MLE)**에서는 이 가능도 함수를 최대화하여 데이터에 가장 잘 맞는 매개변수를 찾습니다. 즉, 주어진 데이터가 가장 잘 설명되도록 하는 매개변수를 추정합니다.\n",
    "  \n",
    "  가능도 함수의 공식은 다음과 같습니다:\n",
    "  $$\n",
    "  L(\\theta \\mid X) = f(X \\mid \\theta)\n",
    "  $$\n",
    "  여기서 `L(θ | X)`는 매개변수 `θ`와 주어진 데이터 `X`를 기준으로 한 가능도 함수입니다. `f(X | θ)`는 매개변수 `θ`에 대한 확률 밀도 함수(PDF) 또는 확률 질량 함수(PMF)입니다.\n",
    "\n",
    "- **3) 예제**\n",
    "  - **동전 던지기**: 동전이 앞면이 나올 확률 `p`를 추정하고자 할 때, 동전을 여러 번 던져서 앞면이 나온 횟수와 뒷면이 나온 횟수를 기록합니다. 가능도 함수는 다음과 같습니다:\n",
    "    $$\n",
    "    L(p \\mid k, n) = p^k (1 - p)^{n - k}\n",
    "    $$\n",
    "    여기서 `k`는 앞면이 나온 횟수, `n`은 전체 던진 횟수입니다. 이 가능도 함수를 최대화하여 `p`의 최적 값을 추정합니다.\n",
    "\n",
    "  - **정규 분포**: 데이터가 정규 분포를 따른다고 가정하고 평균 `μ`과 분산 `σ^2`을 추정하려는 경우, 가능도 함수는 다음과 같습니다:\n",
    "    $$\n",
    "    L(\\mu, \\sigma^2 \\mid X) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2 \\sigma^2}\\right)\n",
    "    $$\n",
    "    여기서 `X`는 관측된 데이터 집합, `μ`은 평균, `σ^2`은 분산입니다.\n",
    "\n",
    "\n",
    "## 3. 최대우도추정\n",
    "\n",
    "#### 1) 정의\n",
    "- 최대우도추정법(MLE)은 주어진 데이터 집합에 대해 매개변수의 값을 선택하여 데이터가 관측될 가능성을 최대화하는 방법입니다. 이는 데이터가 주어진 매개변수 하에서 얼마나 잘 설명되는지를 평가하는 과정입니다.\n",
    "- 일반적으로 MLE에서는 가능도를 최대화하는 매개변수를 찾습니다. 가능도 함수는 특정 매개변수 하에서 데이터가 발생할 확률을 나타냅니다.\n",
    "- 수학적으로 MLE는 다음과 같은 가능도 함수를 최대화하는 매개변수를 찾는 과정입니다:\n",
    "\n",
    "  $$\n",
    "  \\hat{\\theta} = \\arg\\max_{\\theta} \\mathcal{L}(\\theta \\mid X)\n",
    "  $$\n",
    "\n",
    "  여기서, `L(θ | X)`는 매개변수 `θ`와 주어진 데이터 `X`를 기반으로 한 가능도 함수입니다. \n",
    "\n",
    "- 가능도 함수 `L(θ | X)`는 데이터 `X`가 매개변수 `θ`에 따라 관측될 확률을 나타내며, 이를 최대화하여 최적의 매개변수를 추정합니다.\n",
    "\n",
    "#### 2) 예제\n",
    "- **동전 던지기 예제**: 동전이 공평할 확률 `p`을 추정하는 경우, 동전을 `n`번 던져서 `k`번 앞면이 나왔을 때, 가능도 함수는 다음과 같이 주어집니다:\n",
    "\n",
    "  $$\n",
    "  L(p \\mid k, n) = p^k (1 - p)^{n - k}\n",
    "  $$\n",
    "\n",
    "  여기서:\n",
    "  - `k`는 앞면이 나온 횟수\n",
    "  - `n`은 전체 던진 횟수\n",
    "\n",
    "  MLE를 통해 `p`를 최대화하려면, 다음과 같이 로그 가능도 함수(log-likelihood function)를 최대화하는 방법을 사용할 수 있습니다. 로그 가능도 함수는 다음과 같습니다:\n",
    "\n",
    "  $$\n",
    "  \\ell(p \\mid k, n) = \\log L(p \\mid k, n) = k \\log p + (n - k) \\log (1 - p)\n",
    "  $$\n",
    "\n",
    "  로그 가능도를 `p`에 대해 미분하고, 이를 0으로 설정하여 `p`를 추정합니다:\n",
    "\n",
    "  $$\n",
    "  \\frac{d}{dp} \\ell(p \\mid k, n) = \\frac{k}{p} - \\frac{n - k}{1 - p} = 0\n",
    "  $$\n",
    "\n",
    "  위의 방정식을 풀면, `p`의 최적 추정값은 다음과 같습니다:\n",
    "\n",
    "  $$\n",
    "  \\hat{p} = \\frac{k}{n}\n",
    "  $$\n",
    "\n",
    "  즉, 동전을 던져서 앞면이 나온 비율이 동전이 공평할 확률 `p`의 추정값이 됩니다.\n",
    "\n",
    "- **정규 분포의 평균과 분산 추정**: 정규 분포의 경우, 데이터가 `N(μ, σ^2)`로부터 생성되었다고 가정할 때, 평균 `μ`과 분산 `σ^2`을 MLE로 추정할 수 있습니다.\n",
    "  - 평균 `μ`의 추정값은 샘플의 평균입니다:\n",
    "\n",
    "    $$\n",
    "    \\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "    $$\n",
    "\n",
    "  - 분산 `σ^2`의 추정값은 샘플 분산입니다:\n",
    "\n",
    "    $$\n",
    "    \\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\hat{\\mu})^2\n",
    "    $$\n",
    "\n",
    "  이 경우, 데이터의 평균과 분산을 계산하여 정규 분포의 매개변수를 추정합니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 4. 머신러닝에서의 MLE 활용\n",
    "\n",
    "#### 1)회귀 분석 (Regression Analysis)\n",
    "- **선형 회귀 (Linear Regression)**: 선형 회귀 모델에서는 관측된 데이터와 예측 값 사이의 오차를 최소화하는 매개변수를 찾습니다. MLE를 사용하여 회귀 계수를 추정합니다.\n",
    "- **로지스틱 회귀 (Logistic Regression)**: 두 클래스 간의 경계를 모델링하며, MLE를 통해 모델의 매개변수를 추정하여 최적의 분류 경계를 찾습니다.\n",
    "\n",
    "#### 2)혼합 모델 (Mixture Models)\n",
    "- **가우시안 혼합 모델 (Gaussian Mixture Model, GMM)**: 데이터가 여러 개의 가우시안 분포의 혼합으로 구성된다고 가정합니다. MLE를 사용하여 각 가우시안 분포의 평균, 분산, 혼합 비율 등의 매개변수를 추정합니다.\n",
    "\n",
    "#### 3)확률적 그래픽 모델 (Probabilistic Graphical Models)\n",
    "- **HMM (Hidden Markov Model)**: 상태가 시간에 따라 변하는 시스템을 모델링하며, MLE를 사용하여 상태 전이 확률과 관측 확률 등을 추정합니다. EM(Expectation-Maximization) 알고리즘을 통해 수행됩니다.\n",
    "\n",
    "#### 4)클러스터링 (Clustering)\n",
    "- **K-평균 클러스터링 (K-Means Clustering)**: 클러스터의 중심을 추정하는 과정에서 MLE의 원리를 기반으로 합니다. 데이터 포인트가 특정 클러스터에 속할 확률을 최대화하는 방향으로 클러스터 중심을 업데이트합니다.\n",
    "\n",
    "#### 5)파라메트릭 모델 (Parametric Models)\n",
    "- **Naive Bayes Classifier**: 각 클래스의 사전 확률과 클래스 조건부 확률을 추정하는 데 MLE를 사용합니다. 각 클래스의 조건부 확률은 특성의 분포를 기반으로 추정됩니다.\n",
    "\n",
    "### 6) 딥러닝 (Deep Learning)\n",
    "- **신경망 (Neural Networks)**: 신경망에서는 손실 함수가 MLE의 원리를 기반으로 합니다. 예를 들어, 교차 엔트로피 손실(cross-entropy loss)은 MLE의 로그 우도(log-likelihood) 함수로부터 유도됩니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 참고자료\n",
    "\n",
    "  https://psh7286.tistory.com/m/entry/%EC%B5%9C%EB%8C%80%EC%9A%B0%EB%8F%84%EC%B6%94%EC%A0%95-Maximum-likelihood-estimation\n",
    "\n",
    "  https://everyday-tech.tistory.com/entry/%EC%B5%9C%EB%8C%80-%EC%9A%B0%EB%8F%84-%EC%B6%94%EC%A0%95%EB%B2%95Maximum-Likelihood-Estimation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
